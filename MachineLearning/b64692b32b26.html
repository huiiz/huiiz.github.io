<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深度学习相关概念 | HUII's Blog</title><meta name="author" content="HUII"><meta name="copyright" content="HUII"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="持续更新 术语backbone翻译为骨干网络的意思，既然说是主干网络，就代表其是网络的一部分，这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，供后面的网络使用。 这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习相关概念">
<meta property="og:url" content="https://blog.huii.top/MachineLearning/b64692b32b26.html">
<meta property="og:site_name" content="HUII&#39;s Blog">
<meta property="og:description" content="持续更新 术语backbone翻译为骨干网络的意思，既然说是主干网络，就代表其是网络的一部分，这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，供后面的网络使用。 这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.huii.top/img/machinelearning.jpeg">
<meta property="article:published_time" content="2023-03-14T13:18:00.000Z">
<meta property="article:modified_time" content="2025-01-23T10:07:36.126Z">
<meta property="article:author" content="HUII">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="卷积">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.huii.top/img/machinelearning.jpeg"><link rel="shortcut icon" href="/img/logo.png"><link rel="canonical" href="https://blog.huii.top/MachineLearning/b64692b32b26.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":128,"position":"top","messagePrev":"本文最后更新于","messageNext":"天前，其中的信息可能已经有所发展或是发生改变。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: HUII","link":"链接: ","source":"来源: HUII's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习相关概念',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-01-23 18:07:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签云</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/machinelearning.jpeg')"><nav id="nav"><span id="blog-info"><a href="/" title="HUII's Blog"><img class="site-icon" src="/img/logo.png"/><span class="site-name">HUII's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签云</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习相关概念</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-14T13:18:00.000Z" title="发表于 2023-03-14 21:18:00">2023-03-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-23T10:07:36.126Z" title="更新于 2025-01-23 18:07:36">2025-01-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/MachineLearning/">MachineLearning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习相关概念"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>持续更新</p>
<h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><h2 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h2><p>翻译为骨干网络的意思，既然说是主干网络，就代表其是网络的一部分，这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，供后面的网络使用。</p>
<p>这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。</p>
<p><strong>主要分成三类：\</strong>CNNs结构, Transformer结构（如ViT及衍生算法，比如PVT），CNNs+Transformer结构*<em>*</em>。<a target="_blank" rel="noopener" href="https://blog.csdn.net/a486259/article/details/127085783">深度学习常用的backbone有哪些<em>深度学习backbone</em>万里鹏程转瞬至的博客-CSDN博客</a></p>
<p><img src="../img/image-178.png" alt="img">backbone</p>
<p>相关概念还有：</p>
<ul>
<li><p><strong>Neck</strong>：是放在backbone和head之间的，是为了更好的利用backbone提取的特征。</p>
</li>
<li><p><strong>Bottleneck</strong>：瓶颈的意思，通常指的是网网络输入的数据维度和输出的维度不同，输出的维度比输入的小了许多，就像脖子一样，变细了。经常设置的参数 bottle_num=256，指的是网络输出的数据的维度是256 ，可是输入进来的可能是1024维度的。</p>
</li>
<li><p><strong>Head</strong>：head是获取网络输出内容的网络，利用之前提取的特征，head利用这些特征，做出预测。</p>
</li>
</ul>
<h2 id="concat与add"><a href="#concat与add" class="headerlink" title="concat与add"></a>concat与add</h2><p>这是两种深度特征融合方式。</p>
<ul>
<li>concat是通道数的增加，也就是说描述图像本身的特征数（通道数）增加了，而每一特征下的信息是没有增加；横向或纵向空间上的叠加.</li>
<li>add为简单的像素叠加,是描述图像的特征下的信息量增多了，但是描述图像的维度本身并没有增加，只是每一维下的信息量在增加，这显然是对最终的图像的分类是有益的<a target="_blank" rel="noopener" href="https://blog.csdn.net/xyxuyue/article/details/115168218?ops_request_misc=%7B%22request%5Fid%22%3A%22165037838016781683945218%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=165037838016781683945218&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2">卷积中add与concat操作区别及作用<em>卷积层怎么concat</em>小嘿嘿a的博客-CSDN博客</a>。</li>
</ul>
<p>add</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def _merge_function(self, inputs):</span><br><span class="line">    output = inputs[0]</span><br><span class="line">    for i in range(1, len(inputs)):</span><br><span class="line">        output += inputs[i]</span><br><span class="line">    return output</span><br></pre></td></tr></table></figure>
<p>concat</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">t1 = [[1, 2, 3], [4, 5, 6]]</span><br><span class="line">t2 = [[7, 8, 9], [10, 11, 12]]</span><br><span class="line">tf.concat([t1, t2], 0) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]</span><br><span class="line">tf.concat([t1, t2], 1) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]</span><br><span class="line"></span><br><span class="line"># tensor t3 with shape [2, 3]</span><br><span class="line"># tensor t4 with shape [2, 3]</span><br><span class="line">tf.shape(tf.concat([t3, t4], 0)) ==&gt; [4, 3]</span><br><span class="line">tf.shape(tf.concat([t3, t4], 1)) ==&gt; [2, 6]</span><br></pre></td></tr></table></figure>
<h2 id="消融实验ablation-study"><a href="#消融实验ablation-study" class="headerlink" title="消融实验ablation study"></a>消融实验ablation study</h2><p>ablation study往往是在论文最终提出的模型上，减少一些改进特征（如减少几层网络等），以验证相应改进特征的必要性。<a target="_blank" rel="noopener" href="https://blog.csdn.net/PolarisRisingWar/article/details/123557940">什么是ablation study（消融实验）？_诸神缄默不语的博客-CSDN博客</a></p>
<p>消融实验类似于之前学习实验方法中的控制变量法，在一个实验中，涉及到a,b,c三个部分，不知道那个部分对实验起到效果，如果想知道a部分对整个实验的作用，去掉a部分，从而知道a在实验中起到的效果。<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_49148527/article/details/121250234">什么是消融实验（Ablation experiment）？_康司淡定的博客-CSDN博客</a></p>
<h2 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h2><p>State-Of-The-Art，指在公开的数据集上，目前检测到的效果，识别率最高，正确率最高，算法模型最顶的。</p>
<h2 id="FLOPS与FLOPs"><a href="#FLOPS与FLOPs" class="headerlink" title="FLOPS与FLOPs"></a>FLOPS与FLOPs</h2><p>FLOPS：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为<strong>计算速度</strong>。是一个衡量硬件性能的指标。</p>
<p>FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为<strong>计算量</strong>。可以用来衡量算法/模型的复杂度。<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41834400/article/details/120283103">深度学习中的FLOPs介绍及计算(注意区分FLOPS)<strong>_Jupiter</strong>的博客-CSDN博客</a><br>计算方法可以参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41834400/article/details/120283103">深度学习中的FLOPs介绍及计算(注意区分FLOPS)<strong>_Jupiter</strong>的博客-CSDN博客</a></p>
<h1 id="模型算法评估指标"><a href="#模型算法评估指标" class="headerlink" title="模型算法评估指标"></a>模型算法评估指标</h1><h2 id="Top-1错误率、Top-5错误率"><a href="#Top-1错误率、Top-5错误率" class="headerlink" title="Top-1错误率、Top-5错误率"></a>Top-1错误率、Top-5错误率</h2><p>对于分类任务来说，会将分类结果概率进行排序，取<strong>前面5个最大的分类概率</strong>，正确的标签（分类）有没有在里面，如果是，就是分类成功。Top-5正确率此时等于：<strong><em>所有测试图片中正确标签在前五个分类概率的个数/所有的测试图片数</em></strong>。Top-5错误率就是<strong><em>正确标记的样本数不在前五个概率里面的样本数/总的样本数</em></strong>。<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_26413875/article/details/100542817">如何理解论文中常见的Top-1错误率和Top-5错误率？<em>论文里的top误差</em>君子当自强不息的博客-CSDN博客</a></p>
<p>Top-1正确率与Top-1错误率则是讨论预测输出的<strong>概率最高的类别</strong>与人工标注的类别相符的准确率<a target="_blank" rel="noopener" href="https://blog.csdn.net/baidu_41774120/article/details/128992315">Top-1错误率、Top-5错误率等常见的模型算法评估指标解析<em>top5错误率</em>你好，明天，，的博客-CSDN博客</a>。Top-1错误率就是<strong><em>正确标记的样本数不是最佳概率的样本数/总的样本数</em></strong>。<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_26413875/article/details/100542817">如何理解论文中常见的Top-1错误率和Top-5错误率？<em>论文里的top误差</em>君子当自强不息的博客-CSDN博客</a></p>
<h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><h2 id="valid卷积"><a href="#valid卷积" class="headerlink" title="valid卷积"></a>valid卷积</h2><p>下采样卷积，卷积核不能超过特征图的范围($Padding=0$)。$D<em>{output}={\frac{D</em>{input}-D<em>{kernel}+2Padding}{S</em>{kernel}}}+1$。其中$S<em>{kernel}$表示卷积核步长，$D</em>{kernel}$表示卷积核的维度，$Padding$表示扩充值的维度。</p>
<p><img src="../img/image-174.png" alt="img">valid卷积</p>
<h2 id="full卷积"><a href="#full卷积" class="headerlink" title="full卷积"></a>full卷积</h2><p>上采样卷积，卷积核可以超过特征图的范围，但是卷积核边缘要与特征图边缘有交点。</p>
<p><img src="../img/image-176.png" alt="img">full卷积</p>
<h2 id="same卷积"><a href="#same卷积" class="headerlink" title="same卷积"></a>same卷积</h2><p>保持特征图尺寸卷积前后不变。假设输入特征尺度为$n \times n$，则$n={\frac{n-D<em>{kernel}+2Padding}{S</em>{kernel}}}+1$，则$Padding={\frac{1}{2}}({\frac{n-1}{S<em>{kernel}}}-n+D</em>{kernel})$。</p>
<p><img src="../img/image-175.png" alt="img">same卷积</p>
<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><h2 id="SPP结构"><a href="#SPP结构" class="headerlink" title="SPP结构"></a>SPP结构</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.4729">[1406.4729] Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition (arxiv.org)</a></p>
<p>Spatial Pyramid Pooling，空间金字塔池化，使得任意大小的特征图都能够转换成固定大小的特征向量，这就是空间金字塔池化的意义（多尺度特征提取出固定大小的特征向量），送入全连接层。具体算法的大体流程： <strong>输入图像，进行多尺度提取特征，融合特征，传入全连接层</strong>。</p>
<p>解决了多尺度问题。</p>
<p><img src="../img/image-177-1024x682.png" alt="img">spp</p>
<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.03144">[1612.03144] Feature Pyramid Networks for Object Detection (arxiv.org)</a></p>
<p>Feature Pyramid Networks，<strong>特征图金字塔网络</strong>，将不同特征图上的特征进行融合，在融合之后的特征图上再进行预测。FPN是一个利用深度卷积神经网络中固有的多尺度特征图，通过加入侧向连接和上采样，来以极小的附加计算量构建不同尺度的具有高级语义信息的特征金字塔的网络结构。</p>
<p>对于目标检测模型而言，FPN结构并不是模型中独立的一个模块，而是作为原始Backbone的附加项，融合在卷积神经网络之中。<a target="_blank" rel="noopener" href="https://blog.csdn.net/STATEABC/article/details/123921001">FPN结构详解_STATEABC的博客-CSDN博客</a></p>
<p><img src="../img/image-180.png" alt="img">FPN网络结构</p>
<p><img src="../img/image-179.png" alt="img">FPN结构<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1dh411U7D9/">1.1.2 FPN结构详解_哔哩哔哩_bilibili</a></p>
<h2 id="PAN"><a href="#PAN" class="headerlink" title="PAN"></a>PAN</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.01534">[1803.01534] Path Aggregation Network for Instance Segmentation (arxiv.org)</a></p>
<p>Path Aggregation Network，路径聚合网络。</p>
<p>在FPN的自上而下形成的特征金字塔的基础上，来以下这波操作就是PAN啦</p>
<ol>
<li>先复制特征金字塔中最底下的那层（P2），变成新特征金字塔的最底层(N2)。</li>
<li>将新特征金字塔的最底层(N2)来一个下采样操作，然后原特征金字塔的倒数第二层进行一个3 <em> 3卷积，步幅为2；然后与下采样后的最底层进行一个横向连接，两者相加。最后再来一个3 </em> 3卷积来融合他们的特征。</li>
<li>新特征金字塔其他层的操作与2一致。</li>
</ol>
<p><img src="../img/image-181-1024x346.png" alt="img">PAN</p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><h2 id="Swish"><a href="#Swish" class="headerlink" title="Swish"></a>Swish</h2><p>Swish 激活函数：f(x) = x · sigmoid(x)。</p>
<p><img src="../img/image-182-1024x445.png" alt="img">swish激活函数</p>
<p>谷歌大脑团队提出该激活函数，他们的实验表明，在一些具有挑战性的数据集上，Swish 比 ReLU 在更深层次的模型上工作得更好。例如，只需简单地用 Swish 单位替换 ReLUs，Mobile NASNetA 和 inception-resnet-v2的 ImageNet 上的前1分类准确率分别提高了0.9% 和0.6% 。Swish 的简单性及其与 ReLU 的相似性使得从业者可以很容易地在任何神经网络中用 Swish 单元替换 ReLUs。<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38890412/article/details/121494644">详解激活函数Swish<em>swish激活函数</em>越来越胖的GuanRunwei的博客-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30332306">谷歌大脑提出新型激活函数Swish惹争议：可直接替换并优于ReLU？（附机器之心测试） - 知乎 (zhihu.com)</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://blog.huii.top">HUII</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.huii.top/MachineLearning/b64692b32b26.html">https://blog.huii.top/MachineLearning/b64692b32b26.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.huii.top" target="_blank">HUII's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a><a class="post-meta__tags" href="/tags/%E5%8D%B7%E7%A7%AF/">卷积</a></div><div class="post_share"><div class="social-share" data-image="/img/machinelearning.jpeg" data-sites="qq,wechat,weibo,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Coding/0888b8bc6f75.html" title="Python第三方库yaml"><img class="cover" src="/img/python.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python第三方库yaml</div></div></a></div><div class="next-post pull-right"><a href="/Coding/9ae26d15f5a2.html" title="Linux的文件权限"><img class="cover" src="/img/linux.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux的文件权限</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/MachineLearning/9de011f33507.html" title="Fast R-CNN——RCNN系列算法Ⅱ"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-23</div><div class="title">Fast R-CNN——RCNN系列算法Ⅱ</div></div></a></div><div><a href="/MachineLearning/b91d8b42ccc3.html" title="Faster R-CNN——RCNN系列算法Ⅲ"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-27</div><div class="title">Faster R-CNN——RCNN系列算法Ⅲ</div></div></a></div><div><a href="/MachineLearning/794a5634681d.html" title="R-CNN——RCNN系列算法Ⅰ"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-21</div><div class="title">R-CNN——RCNN系列算法Ⅰ</div></div></a></div><div><a href="/MachineLearning/4543f3866cda.html" title="YOLO v1笔记"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-12</div><div class="title">YOLO v1笔记</div></div></a></div><div><a href="/MachineLearning/ea6e3c43cae3.html" title="YOLOv3笔记"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-11</div><div class="title">YOLOv3笔记</div></div></a></div><div><a href="/MachineLearning/d808d6f21a58.html" title="图像目标检测基本概念与算法"><img class="cover" src="/img/machinelearning.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">图像目标检测基本概念与算法</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%AF%E8%AF%AD"><span class="toc-number">1.</span> <span class="toc-text">术语</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#backbone"><span class="toc-number">1.1.</span> <span class="toc-text">backbone</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#concat%E4%B8%8Eadd"><span class="toc-number">1.2.</span> <span class="toc-text">concat与add</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8Cablation-study"><span class="toc-number">1.3.</span> <span class="toc-text">消融实验ablation study</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SOTA"><span class="toc-number">1.4.</span> <span class="toc-text">SOTA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FLOPS%E4%B8%8EFLOPs"><span class="toc-number">1.5.</span> <span class="toc-text">FLOPS与FLOPs</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">2.</span> <span class="toc-text">模型算法评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Top-1%E9%94%99%E8%AF%AF%E7%8E%87%E3%80%81Top-5%E9%94%99%E8%AF%AF%E7%8E%87"><span class="toc-number">2.1.</span> <span class="toc-text">Top-1错误率、Top-5错误率</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">3.</span> <span class="toc-text">卷积层</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#valid%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.1.</span> <span class="toc-text">valid卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#full%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.2.</span> <span class="toc-text">full卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#same%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.3.</span> <span class="toc-text">same卷积</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">4.</span> <span class="toc-text">网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SPP%E7%BB%93%E6%9E%84"><span class="toc-number">4.1.</span> <span class="toc-text">SPP结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FPN"><span class="toc-number">4.2.</span> <span class="toc-text">FPN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PAN"><span class="toc-number">4.3.</span> <span class="toc-text">PAN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">5.</span> <span class="toc-text">激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Swish"><span class="toc-number">5.1.</span> <span class="toc-text">Swish</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/img/machinelearning.jpeg')"><div id="footer-wrap"><div class="copyright">&copy;2015 - 2025 By HUII</div><div class="footer_custom_text"><span>备案号：<a href="https://beian.miit.gov.cn/" target="_blank">闽ICP备18005042号-2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'ce436d2d4a3e549dad64',
      clientSecret: '9a40a66c694e77b58120d1b62b2dcee193963143',
      repo: 'huiiz.github.io',
      owner: 'huiiz',
      admin: ['huiiz'],
      id: '3d3e10b7766aa2d9eb7c51206813af02',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><div style="display:none;"><script type="text/javascript" src="https://v1.cnzz.com/z_stat.php?id=1279897347&web_id=1279897347"></script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>